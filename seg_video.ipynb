{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8421fd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdai/anaconda3/envs/DLpy37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/zdai/anaconda3/envs/DLpy37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/zdai/anaconda3/envs/DLpy37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/zdai/anaconda3/envs/DLpy37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/zdai/anaconda3/envs/DLpy37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/zdai/anaconda3/envs/DLpy37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/zdai/anaconda3/envs/DLpy37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/zdai/anaconda3/envs/DLpy37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/zdai/anaconda3/envs/DLpy37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/zdai/anaconda3/envs/DLpy37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/zdai/anaconda3/envs/DLpy37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/zdai/anaconda3/envs/DLpy37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#put the these lines before importing any module from keras.\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
    "config.gpu_options.visible_device_list = \"0\" #only the gpu 0 is allowed\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "graph = tf.get_default_graph()\n",
    "set_session(sess)\n",
    "\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5e63b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import keras\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib auto\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, add, LSTM, RepeatVector, TimeDistributed, concatenate, Conv2DTranspose, Add\n",
    "from keras.layers.core import Layer, Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras_segmentation.models.model_utils import get_segmentation_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dba04523",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.2\n"
     ]
    }
   ],
   "source": [
    "vidcap = cv2.VideoCapture(join('dataset2', 'SampleASAPSData.mp4'))\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e5a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "776533bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps = 30.0\n",
      "number of frames = 30211\n",
      "duration (S) = 1007.0333333333333\n",
      "duration (M:S) = 16:47.0333333333333\n"
     ]
    }
   ],
   "source": [
    "fps = vidcap.get(cv2.CAP_PROP_FPS)      # OpenCV2 version 2 used \"CV_CAP_PROP_FPS\"\n",
    "frame_count = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = frame_count/fps\n",
    "\n",
    "print('fps = ' + str(fps))\n",
    "print('number of frames = ' + str(frame_count))\n",
    "print('duration (S) = ' + str(duration))\n",
    "minutes = int(duration/60)\n",
    "seconds = duration%60\n",
    "print('duration (M:S) = ' + str(minutes) + ':' + str(seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59286c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "while vidcap.isOpened():\n",
    "    success, image = vidcap.read()\n",
    "    if success:\n",
    "        \n",
    "        #cv2.imshow('Images', image)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        if count >= 11200 and count < 11700:\n",
    "            cv2.imwrite(\"dataset2/images/frame%d.png\" % count, image)\n",
    "        elif count >= 12000:\n",
    "            break\n",
    "        \n",
    "        count += 1\n",
    "    else:\n",
    "        print(\"Read Image from Video Failed!\")\n",
    "        break\n",
    "        \n",
    "vidcap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55527fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = join('dataset2', 'images')\n",
    "\n",
    "height, width = 224, 224\n",
    "\n",
    "image0 = cv2.imread(join(data_dir, 'frame11386.png'))\n",
    "img0 = cv2.resize(image0, (width, height))\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "\n",
    "ax1 = fig.add_subplot(2,1,1)\n",
    "ax1.imshow(image0)\n",
    "ax2 = fig.add_subplot(2,1,2)\n",
    "ax2.imshow(img0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d78bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zdai/anaconda3/envs/DLpy37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 224, 224, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 224, 224, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 224, 224, 32) 9248        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 112, 112, 32) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 112, 112, 64) 18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 112, 112, 64) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 112, 112, 64) 36928       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 56, 56, 128)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 128)  147584      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 112, 112, 128 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_1[0][0]            \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 112, 112, 64) 110656      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 112, 112, 64) 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 112, 112, 64) 36928       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 224, 224, 64) 0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 224, 224, 96) 0           up_sampling2d_2[0][0]            \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 224, 224, 32) 27680       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 224, 224, 32) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 224, 224, 32) 9248        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 224, 224, 12) 396         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 50176, 12)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 50176, 12)    0           reshape_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 471,916\n",
      "Trainable params: 471,916\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "from keras_segmentation.models.unet import unet_mini, vgg_unet\n",
    "\n",
    "model0 = unet_mini(n_classes=12 ,  input_height=height, input_width=width )\n",
    "model0.summary()\n",
    "\n",
    "model0.load_weights(join('checkpoints', 'mini_unet0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf89b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_color_to_seg_img(seg, n_classes):\n",
    "    '''\n",
    "    seg : (input_width,input_height,3)\n",
    "    '''\n",
    "    \n",
    "    if len(seg.shape)==3:\n",
    "        seg = seg[:,:,0]\n",
    "    seg_img = np.zeros( (seg.shape[0],seg.shape[1],3) ).astype('float')\n",
    "    colors = sns.color_palette(\"hls\", n_classes)\n",
    "    \n",
    "    for c in range(n_classes):\n",
    "        segc = (seg == c)\n",
    "        seg_img[:,:,0] += (segc*( colors[c][0] ))\n",
    "        seg_img[:,:,1] += (segc*( colors[c][1] ))\n",
    "        seg_img[:,:,2] += (segc*( colors[c][2] ))\n",
    "\n",
    "    return(seg_img)\n",
    "\n",
    "def getImageArr( path , width , height ):\n",
    "        img = cv2.imread(path, 1)\n",
    "        img = np.float32(cv2.resize(img, ( width , height ))) / 127.5 - 1\n",
    "        return img\n",
    "\n",
    "def getSegmentationArr( path , nClasses ,  width , height  ):\n",
    "\n",
    "    seg_labels = np.zeros((  height , width  , nClasses ))\n",
    "    img = cv2.imread(path, 1)\n",
    "    img = cv2.resize(img, ( width , height ))\n",
    "    img = img[:, : , 0]\n",
    "\n",
    "    for c in range(nClasses):\n",
    "        seg_labels[: , : , c ] = (img == c ).astype(int)\n",
    "    ##seg_labels = np.reshape(seg_labels, ( width*height,nClasses  ))\n",
    "    return seg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69ebc4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test0 = img0.reshape(1, height, width, 3)\n",
    "y_pred = model0.predict(x_test0).reshape(-1, height, width, 12)\n",
    "y_predi = np.argmax(y_pred, axis=3)\n",
    "\n",
    "print(y_predi.shape)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f53f5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred0 = y_pred.reshape(height, width, 12)\n",
    "\n",
    "plt.imshow(give_color_to_seg_img(y_pred0, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434db90d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
